{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import os \n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import sagemaker\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset, Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, TrainingArguments, Trainer, T5ForConditionalGeneration,T5Tokenizer\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# if running on GPU instance, enable Torch, otherwise use CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# specify execution role\n",
    "#role = sagemaker.get_execution_role()\n",
    "# specify bucket\n",
    "bucket = 'sagemaker-eu-west-1-177767430422'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to look at scale of win for clickthrough \n",
    "\n",
    "can try using classification and embeddings\n",
    "\n",
    "Should generate embeddings for each headline version and then do some clustering. Visualize the embeddings and look for patterns.\n",
    "\n",
    "Can try using GPT-2 instead of the squeezebert model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>post_date</th>\n",
       "      <th>title_a</th>\n",
       "      <th>title_b</th>\n",
       "      <th>title_a_impressions</th>\n",
       "      <th>title_b_impressions</th>\n",
       "      <th>title_a_clicks</th>\n",
       "      <th>title_b_clicks</th>\n",
       "      <th>title_a_rate</th>\n",
       "      <th>title_b_rate</th>\n",
       "      <th>winner</th>\n",
       "      <th>confidence</th>\n",
       "      <th>title_rate_diff</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1774776</td>\n",
       "      <td>6/20/2021 6:01:24 PM</td>\n",
       "      <td>Porsche will build a high-performance battery ...</td>\n",
       "      <td>Porsche is building a battery factory for moto...</td>\n",
       "      <td>1060</td>\n",
       "      <td>1005</td>\n",
       "      <td>65</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0613</td>\n",
       "      <td>0.0498</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1774704</td>\n",
       "      <td>6/21/2021 6:00:57 AM</td>\n",
       "      <td>Sony’s excellent WH-1000XM4 headphones are dow...</td>\n",
       "      <td>A couple of our favorite wireless headphones a...</td>\n",
       "      <td>788</td>\n",
       "      <td>826</td>\n",
       "      <td>82</td>\n",
       "      <td>66</td>\n",
       "      <td>0.1041</td>\n",
       "      <td>0.0799</td>\n",
       "      <td>a</td>\n",
       "      <td>95</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1774658</td>\n",
       "      <td>6/21/2021 4:50:03 AM</td>\n",
       "      <td>Amazon Prime Day 2021: All the deals that are ...</td>\n",
       "      <td>Amazon Prime Day 2021: A mega-roundup of all t...</td>\n",
       "      <td>677</td>\n",
       "      <td>610</td>\n",
       "      <td>81</td>\n",
       "      <td>69</td>\n",
       "      <td>0.1196</td>\n",
       "      <td>0.1131</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1774623</td>\n",
       "      <td>6/20/2021 5:18:52 PM</td>\n",
       "      <td>Review: &lt;em&gt;Hitman’s Wife’s Bodyguard&lt;/em&gt; amp...</td>\n",
       "      <td>&lt;em&gt;The Hitman’s Wife’s Bodyguard&lt;/em&gt; is the ...</td>\n",
       "      <td>846</td>\n",
       "      <td>830</td>\n",
       "      <td>82</td>\n",
       "      <td>139</td>\n",
       "      <td>0.0969</td>\n",
       "      <td>0.1675</td>\n",
       "      <td>b</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0706</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1774586</td>\n",
       "      <td>6/18/2021 9:43:09 AM</td>\n",
       "      <td>Pornhub hosted rape, revenge porn, and child s...</td>\n",
       "      <td>Pornhub sued for allegedly serving “under-age,...</td>\n",
       "      <td>1658</td>\n",
       "      <td>1676</td>\n",
       "      <td>177</td>\n",
       "      <td>214</td>\n",
       "      <td>0.1068</td>\n",
       "      <td>0.1277</td>\n",
       "      <td>b</td>\n",
       "      <td>97</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID             post_date  \\\n",
       "0  1774776  6/20/2021 6:01:24 PM   \n",
       "1  1774704  6/21/2021 6:00:57 AM   \n",
       "2  1774658  6/21/2021 4:50:03 AM   \n",
       "3  1774623  6/20/2021 5:18:52 PM   \n",
       "4  1774586  6/18/2021 9:43:09 AM   \n",
       "\n",
       "                                             title_a  \\\n",
       "0  Porsche will build a high-performance battery ...   \n",
       "1  Sony’s excellent WH-1000XM4 headphones are dow...   \n",
       "2  Amazon Prime Day 2021: All the deals that are ...   \n",
       "3  Review: <em>Hitman’s Wife’s Bodyguard</em> amp...   \n",
       "4  Pornhub hosted rape, revenge porn, and child s...   \n",
       "\n",
       "                                             title_b  title_a_impressions  \\\n",
       "0  Porsche is building a battery factory for moto...                 1060   \n",
       "1  A couple of our favorite wireless headphones a...                  788   \n",
       "2  Amazon Prime Day 2021: A mega-roundup of all t...                  677   \n",
       "3  <em>The Hitman’s Wife’s Bodyguard</em> is the ...                  846   \n",
       "4  Pornhub sued for allegedly serving “under-age,...                 1658   \n",
       "\n",
       "   title_b_impressions  title_a_clicks  title_b_clicks  title_a_rate  \\\n",
       "0                 1005              65              50        0.0613   \n",
       "1                  826              82              66        0.1041   \n",
       "2                  610              81              69        0.1196   \n",
       "3                  830              82             139        0.0969   \n",
       "4                 1676             177             214        0.1068   \n",
       "\n",
       "   title_b_rate winner  confidence  title_rate_diff  label  \n",
       "0        0.0498      a           0           0.0115      0  \n",
       "1        0.0799      a          95           0.0242      0  \n",
       "2        0.1131      a           0           0.0065      0  \n",
       "3        0.1675      b         100           0.0706      1  \n",
       "4        0.1277      b          97           0.0209      1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines = pd.read_csv('ars-headline-tests-no-filter.csv')\n",
    "headlines['title_rate_diff'] = np.abs(headlines.title_a_rate-headlines.title_b_rate)\n",
    "label = []\n",
    "for i,row in headlines.iterrows():\n",
    "#     if row['title_rate_diff']<0.01:\n",
    "#         label.append(2)\n",
    "    if row['winner']=='a':\n",
    "        label.append(0)\n",
    "    else:\n",
    "        label.append(1)\n",
    "headlines['label'] = label\n",
    "headlines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4926.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "        5771.]),\n",
       " array([  0.,  10.,  20.,  30.,  40.,  50.,  60.,  70.,  80.,  90., 100.]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot confidence\n",
    "plt.hist(headlines.confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save headlines with rate above 0.01\n",
    "headlines[headlines.title_rate_diff>0.01].to_csv('sig_diff_headlines.csv', index=False)\n",
    "headlines.to_csv('formatted_headlines.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: 197.8429\n",
      "mean: 0.04461947200898713\n",
      "Number of observations above 1%: 7057\n"
     ]
    }
   ],
   "source": [
    "# get summary stats on headline title rate differential\n",
    "print('max:',np.max(headlines.title_rate_diff))\n",
    "print('mean:', np.mean(headlines.title_rate_diff))\n",
    "print('Number of observations above 1%:',sum(headlines.title_rate_diff>0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.625e+03, 2.548e+03, 1.705e+03, 1.036e+03, 6.540e+02, 3.930e+02,\n",
       "        2.550e+02, 1.560e+02, 9.900e+01, 5.200e+01, 4.400e+01, 1.800e+01,\n",
       "        1.900e+01, 1.400e+01, 1.500e+01, 6.000e+00, 5.000e+00, 2.000e+00,\n",
       "        3.000e+00, 4.000e+00, 0.000e+00, 2.000e+00, 1.000e+00, 0.000e+00,\n",
       "        1.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 1.000e+00, 1.000e+00, 2.000e+00, 0.000e+00,\n",
       "        1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 2.000e+00, 1.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00,\n",
       "        0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00]),\n",
       " array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 ,\n",
       "        0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21,\n",
       "        0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32,\n",
       "        0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43,\n",
       "        0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5 , 0.51, 0.52, 0.53, 0.54,\n",
       "        0.55, 0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65,\n",
       "        0.66, 0.67, 0.68, 0.69, 0.7 , 0.71, 0.72, 0.73, 0.74, 0.75, 0.76,\n",
       "        0.77, 0.78, 0.79, 0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87,\n",
       "        0.88, 0.89, 0.9 , 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98,\n",
       "        0.99, 1.  ]),\n",
       " <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot histogram of rate differential\n",
    "plt.figure(figsize=(14,7))\n",
    "plt.title('Title rate differential histogram')\n",
    "plt.hist(headlines.title_rate_diff, bins=100, range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./formatted_headlines.csv to s3://sagemaker-eu-west-1-177767430422/headlines/formatted_headlines.csv\n",
      "upload: ./sig_diff_headlines.csv to s3://sagemaker-eu-west-1-177767430422/headlines/sig_diff_headlines.csv\n"
     ]
    }
   ],
   "source": [
    "# send data to s3\n",
    "!aws s3 cp formatted_headlines.csv s3://{bucket}/headlines/formatted_headlines.csv\n",
    "!aws s3 cp sig_diff_headlines.csv s3://{bucket}/headlines/sig_diff_headlines.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paraphrase model \n",
    "Can use this as a base for how to setup our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should be paraphrase\n",
      "not paraphrase: 10%\n",
      "is paraphrase: 90%\n",
      "\n",
      "Should not be paraphrase\n",
      "not paraphrase: 94%\n",
      "is paraphrase: 6%\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased-finetuned-mrpc\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased-finetuned-mrpc\")\n",
    "\n",
    "classes = [\"not paraphrase\", \"is paraphrase\"]\n",
    "\n",
    "sequence_0 = \"The company HuggingFace is based in New York City\"\n",
    "sequence_1 = \"Apples are especially bad for your health\"\n",
    "sequence_2 = \"HuggingFace's headquarters are situated in Manhattan\"\n",
    "\n",
    "paraphrase = tokenizer.encode_plus(sequence_0, sequence_2, return_tensors=\"pt\")\n",
    "not_paraphrase = tokenizer.encode_plus(sequence_0, sequence_1, return_tensors=\"pt\")\n",
    "\n",
    "paraphrase_classification_logits = model(**paraphrase)[0]\n",
    "not_paraphrase_classification_logits = model(**not_paraphrase)[0]\n",
    "\n",
    "paraphrase_results = torch.softmax(paraphrase_classification_logits, dim=1).tolist()[0]\n",
    "not_paraphrase_results = torch.softmax(not_paraphrase_classification_logits, dim=1).tolist()[0]\n",
    "\n",
    "print(\"Should be paraphrase\")\n",
    "for i in range(len(classes)):\n",
    "    print(f\"{classes[i]}: {round(paraphrase_results[i] * 100)}%\")\n",
    "\n",
    "print(\"\\nShould not be paraphrase\")\n",
    "for i in range(len(classes)):\n",
    "    print(f\"{classes[i]}: {round(not_paraphrase_results[i] * 100)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model locally\n",
    "\n",
    "We can try several models to finetune, the squeezebert model works relatively well, more powerful models like GPT-2 will likely work even better. We are focusing on models pretrained on large amounts of news text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0555f4081674880a84185f368601792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=500, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a867da0249c461c8ad9fe11d67c800f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=231580, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a3c1a5566a6476a8fea012ee33d93e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=466182, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db90755bb27f4e4e9bded4269682f12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=202049872, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SqueezeBertForSequenceClassification were not initialized from the model checkpoint at squeezebert/squeezebert-mnli-headless and are newly initialized: ['transformer.pooler.dense.weight', 'classifier.weight', 'classifier.bias', 'transformer.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SqueezeBertForSequenceClassification(\n",
       "  (transformer): SqueezeBertModel(\n",
       "    (embeddings): SqueezeBertEmbeddings(\n",
       "      (word_embeddings): Embedding(30528, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): SqueezeBertEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): SqueezeBertModule(\n",
       "          (attention): SqueezeBertSelfAttention(\n",
       "            (query): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (key): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (value): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (matmul_qk): MatMulWrapper()\n",
       "            (matmul_qkv): MatMulWrapper()\n",
       "          )\n",
       "          (post_attention): ConvDropoutLayerNorm(\n",
       "            (conv1d): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "            (layernorm): SqueezeBertLayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate): ConvActivation(\n",
       "            (conv1d): Conv1d(768, 3072, kernel_size=(1,), stride=(1,), groups=4)\n",
       "          )\n",
       "          (output): ConvDropoutLayerNorm(\n",
       "            (conv1d): Conv1d(3072, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (layernorm): SqueezeBertLayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SqueezeBertModule(\n",
       "          (attention): SqueezeBertSelfAttention(\n",
       "            (query): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (key): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (value): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (matmul_qk): MatMulWrapper()\n",
       "            (matmul_qkv): MatMulWrapper()\n",
       "          )\n",
       "          (post_attention): ConvDropoutLayerNorm(\n",
       "            (conv1d): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "            (layernorm): SqueezeBertLayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate): ConvActivation(\n",
       "            (conv1d): Conv1d(768, 3072, kernel_size=(1,), stride=(1,), groups=4)\n",
       "          )\n",
       "          (output): ConvDropoutLayerNorm(\n",
       "            (conv1d): Conv1d(3072, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (layernorm): SqueezeBertLayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): SqueezeBertModule(\n",
       "          (attention): SqueezeBertSelfAttention(\n",
       "            (query): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (key): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (value): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (matmul_qk): MatMulWrapper()\n",
       "            (matmul_qkv): MatMulWrapper()\n",
       "          )\n",
       "          (post_attention): ConvDropoutLayerNorm(\n",
       "            (conv1d): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "            (layernorm): SqueezeBertLayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate): ConvActivation(\n",
       "            (conv1d): Conv1d(768, 3072, kernel_size=(1,), stride=(1,), groups=4)\n",
       "          )\n",
       "          (output): ConvDropoutLayerNorm(\n",
       "            (conv1d): Conv1d(3072, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (layernorm): SqueezeBertLayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): SqueezeBertModule(\n",
       "          (attention): SqueezeBertSelfAttention(\n",
       "            (query): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (key): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (value): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (matmul_qk): MatMulWrapper()\n",
       "            (matmul_qkv): MatMulWrapper()\n",
       "          )\n",
       "          (post_attention): ConvDropoutLayerNorm(\n",
       "            (conv1d): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "            (layernorm): SqueezeBertLayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate): ConvActivation(\n",
       "            (conv1d): Conv1d(768, 3072, kernel_size=(1,), stride=(1,), groups=4)\n",
       "          )\n",
       "          (output): ConvDropoutLayerNorm(\n",
       "            (conv1d): Conv1d(3072, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (layernorm): SqueezeBertLayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): SqueezeBertModule(\n",
       "          (attention): SqueezeBertSelfAttention(\n",
       "            (query): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (key): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (value): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (matmul_qk): MatMulWrapper()\n",
       "            (matmul_qkv): MatMulWrapper()\n",
       "          )\n",
       "          (post_attention): ConvDropoutLayerNorm(\n",
       "            (conv1d): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "            (layernorm): SqueezeBertLayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate): ConvActivation(\n",
       "            (conv1d): Conv1d(768, 3072, kernel_size=(1,), stride=(1,), groups=4)\n",
       "          )\n",
       "          (output): ConvDropoutLayerNorm(\n",
       "            (conv1d): Conv1d(3072, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (layernorm): SqueezeBertLayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): SqueezeBertModule(\n",
       "          (attention): SqueezeBertSelfAttention(\n",
       "            (query): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (key): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (value): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (matmul_qk): MatMulWrapper()\n",
       "            (matmul_qkv): MatMulWrapper()\n",
       "          )\n",
       "          (post_attention): ConvDropoutLayerNorm(\n",
       "            (conv1d): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "            (layernorm): SqueezeBertLayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate): ConvActivation(\n",
       "            (conv1d): Conv1d(768, 3072, kernel_size=(1,), stride=(1,), groups=4)\n",
       "          )\n",
       "          (output): ConvDropoutLayerNorm(\n",
       "            (conv1d): Conv1d(3072, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (layernorm): SqueezeBertLayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): SqueezeBertModule(\n",
       "          (attention): SqueezeBertSelfAttention(\n",
       "            (query): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (key): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (value): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (matmul_qk): MatMulWrapper()\n",
       "            (matmul_qkv): MatMulWrapper()\n",
       "          )\n",
       "          (post_attention): ConvDropoutLayerNorm(\n",
       "            (conv1d): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "            (layernorm): SqueezeBertLayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate): ConvActivation(\n",
       "            (conv1d): Conv1d(768, 3072, kernel_size=(1,), stride=(1,), groups=4)\n",
       "          )\n",
       "          (output): ConvDropoutLayerNorm(\n",
       "            (conv1d): Conv1d(3072, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (layernorm): SqueezeBertLayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): SqueezeBertModule(\n",
       "          (attention): SqueezeBertSelfAttention(\n",
       "            (query): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (key): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (value): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (matmul_qk): MatMulWrapper()\n",
       "            (matmul_qkv): MatMulWrapper()\n",
       "          )\n",
       "          (post_attention): ConvDropoutLayerNorm(\n",
       "            (conv1d): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "            (layernorm): SqueezeBertLayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate): ConvActivation(\n",
       "            (conv1d): Conv1d(768, 3072, kernel_size=(1,), stride=(1,), groups=4)\n",
       "          )\n",
       "          (output): ConvDropoutLayerNorm(\n",
       "            (conv1d): Conv1d(3072, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (layernorm): SqueezeBertLayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): SqueezeBertModule(\n",
       "          (attention): SqueezeBertSelfAttention(\n",
       "            (query): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (key): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (value): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (matmul_qk): MatMulWrapper()\n",
       "            (matmul_qkv): MatMulWrapper()\n",
       "          )\n",
       "          (post_attention): ConvDropoutLayerNorm(\n",
       "            (conv1d): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "            (layernorm): SqueezeBertLayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate): ConvActivation(\n",
       "            (conv1d): Conv1d(768, 3072, kernel_size=(1,), stride=(1,), groups=4)\n",
       "          )\n",
       "          (output): ConvDropoutLayerNorm(\n",
       "            (conv1d): Conv1d(3072, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (layernorm): SqueezeBertLayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): SqueezeBertModule(\n",
       "          (attention): SqueezeBertSelfAttention(\n",
       "            (query): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (key): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (value): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (matmul_qk): MatMulWrapper()\n",
       "            (matmul_qkv): MatMulWrapper()\n",
       "          )\n",
       "          (post_attention): ConvDropoutLayerNorm(\n",
       "            (conv1d): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "            (layernorm): SqueezeBertLayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate): ConvActivation(\n",
       "            (conv1d): Conv1d(768, 3072, kernel_size=(1,), stride=(1,), groups=4)\n",
       "          )\n",
       "          (output): ConvDropoutLayerNorm(\n",
       "            (conv1d): Conv1d(3072, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (layernorm): SqueezeBertLayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): SqueezeBertModule(\n",
       "          (attention): SqueezeBertSelfAttention(\n",
       "            (query): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (key): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (value): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (matmul_qk): MatMulWrapper()\n",
       "            (matmul_qkv): MatMulWrapper()\n",
       "          )\n",
       "          (post_attention): ConvDropoutLayerNorm(\n",
       "            (conv1d): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "            (layernorm): SqueezeBertLayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate): ConvActivation(\n",
       "            (conv1d): Conv1d(768, 3072, kernel_size=(1,), stride=(1,), groups=4)\n",
       "          )\n",
       "          (output): ConvDropoutLayerNorm(\n",
       "            (conv1d): Conv1d(3072, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (layernorm): SqueezeBertLayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): SqueezeBertModule(\n",
       "          (attention): SqueezeBertSelfAttention(\n",
       "            (query): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (key): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (value): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (matmul_qk): MatMulWrapper()\n",
       "            (matmul_qkv): MatMulWrapper()\n",
       "          )\n",
       "          (post_attention): ConvDropoutLayerNorm(\n",
       "            (conv1d): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "            (layernorm): SqueezeBertLayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate): ConvActivation(\n",
       "            (conv1d): Conv1d(768, 3072, kernel_size=(1,), stride=(1,), groups=4)\n",
       "          )\n",
       "          (output): ConvDropoutLayerNorm(\n",
       "            (conv1d): Conv1d(3072, 768, kernel_size=(1,), stride=(1,), groups=4)\n",
       "            (layernorm): SqueezeBertLayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): SqueezeBertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "model_checkpoint = 'squeezebert/squeezebert-mnli-headless'\n",
    "# \"Michau/t5-base-en-generate-headline\"\n",
    "# QianWeiTech/GPT2-News\n",
    "# squeezebert/squeezebert-mnli-headless\n",
    "# in order to use any of these models we need to have a tokenizer.\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "\n",
    "# number of output labels\n",
    "num_labels = 2\n",
    "# while the original model was trained in a \"masked language model\" format, we can finetune it for a different task, in this case sequence classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)\n",
    "# send model to GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format our data\n",
    "\n",
    "To use HF for training we need to put our data into their format. Here we are loading our CSV file and then we will tokenize the inputs so the model can training on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-af6c617adf595a0f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /home/sean/.cache/huggingface/datasets/csv/default-af6c617adf595a0f/0.0.0/e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8739fa60baf4ea8bb2f90a75a03ef6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/sean/.cache/huggingface/datasets/csv/default-af6c617adf595a0f/0.0.0/e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ID', 'post_date', 'title_a', 'title_b', 'title_a_impressions', 'title_b_impressions', 'title_a_clicks', 'title_b_clicks', 'title_a_rate', 'title_b_rate', 'winner', 'confidence', 'title_rate_diff', 'label'],\n",
       "        num_rows: 10697\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load labels as HF dataset\n",
    "dataset = load_dataset('csv', data_files='formatted_headlines.csv') # 'ars-headline-tests-no-filter.csv')\n",
    "# eval_dataset = load_dataset('csv', data_files='eval_frame.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using GPT2 need to add PAD token\n",
    "# tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "# tokenizer(text=dataset['train']['title_a'][0],text_pair = dataset['train']['title_b'][0], truncation=True, max_length=512, padding='max_length')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porsche will build a high-performance battery factory in Germany \n",
      " Porsche is building a battery factory for motorsport and performance EVs \n",
      "\n",
      "{'input_ids': [101, 16099, 2097, 3857, 1037, 2152, 1011, 2836, 6046, 4713, 1999, 2762, 102, 16099, 2003, 2311, 1037, 6046, 4713, 2005, 21044, 1998, 2836, 23408, 2015, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "# run example tokenization \n",
    "print(dataset['train']['title_a'][0], '\\n',dataset['train']['title_b'][0], '\\n')\n",
    "tokens = tokenizer.encode_plus(text=dataset['train']['title_a'][0],text_pair = dataset['train']['title_b'][0], truncation=True, padding='max_length')\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10697/10697 [06:03<00:00, 29.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# tokenize your inputs \n",
    "input_ids = []\n",
    "token_type_ids = []\n",
    "attention_masks = []\n",
    "label = []\n",
    "for i in tqdm(range(len(dataset['train']))):\n",
    "    token = tokenizer.encode_plus(dataset['train']['title_a'][i],dataset['train']['title_b'][i], truncation=True, padding='max_length')\n",
    "    input_ids.append(np.array(token['input_ids'], dtype=np.int32))\n",
    "    token_type_ids.append(np.array(token['token_type_ids'], dtype=np.int32))\n",
    "    attention_masks.append(np.array(token['attention_mask'], dtype=np.int32))\n",
    "    label.append(dataset['train']['label'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our split\n",
    "split_ind = int(.95*len(dataset['train']))\n",
    "# reform datasets into two separate dictionaries \n",
    "dataset_dict = {}\n",
    "eval_dataset_dict = {}\n",
    "dataset_dict['input_ids'] = input_ids[:split_ind]\n",
    "dataset_dict['token_type_ids'] = token_type_ids[:split_ind]\n",
    "dataset_dict['attention_mask'] = attention_masks[:split_ind]\n",
    "dataset_dict['label'] = label[:split_ind]\n",
    "\n",
    "eval_dataset_dict['input_ids'] = input_ids[split_ind:]\n",
    "eval_dataset_dict['token_type_ids'] = token_type_ids[split_ind:]\n",
    "eval_dataset_dict['attention_mask'] = attention_masks[split_ind:]\n",
    "eval_dataset_dict['label'] = label[split_ind:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having issues with max length...\n",
    "\n",
    "ArrowInvalid: Column 1 named attention_mask expected length 697 but got length 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # try to use HF dataset mapper, had issues with implementation\n",
    "# def encode(examples, tokenizer):\n",
    "# #     print(examples['title_a'])\n",
    "#     print(examples['title_a'][0], examples['title_b'][0])\n",
    "#     return tokenizer.encode_plus(str(examples['title_a'][0][:]), str(examples['title_b'][0][:]), truncation=True, padding='max_length', max_length=384) # 'max_length'\n",
    "\n",
    "# dataset = dataset.map(encode, batched=True, fn_kwargs={'tokenizer':tokenizer})\n",
    "# # eval_dataset = eval_dataset.map(encode, batched=True, fn_kwargs={'tokenizer':tokenizer})\n",
    "# columns_to_return = ['input_ids', 'label', 'attention_mask']\n",
    "# dataset.set_format(type='torch', columns=columns_to_return)\n",
    "# eval_dataset.set_format(type='torch', columns=columns_to_return)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train and eval sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'label'],\n",
       "    num_rows: 10162\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataset objects from previously created dictionaries \n",
    "train_dataset = Dataset.from_dict(dataset_dict)\n",
    "eval_dataset = Dataset.from_dict(eval_dataset_dict)\n",
    "columns_to_return = ['input_ids', 'label', 'attention_mask']\n",
    "train_dataset.set_format(type='torch', columns=columns_to_return) #, device='cuda')\n",
    "eval_dataset.set_format(type='torch', columns=columns_to_return) #, device='cuda')\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set evaluation function\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training locally\n",
    "\n",
    "If you are using a GPU instance you can run training locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run training locally\n",
    "batch_size = 8\n",
    "metric_name = \"accuracy\"\n",
    "args = TrainingArguments(\n",
    "    \"test-glue\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    ")\n",
    "\n",
    "# it automatically tries to create tensors for you\n",
    "# validation_key = \"validation_mismatched\" if task == \"mnli-mm\" else \"validation_matched\" if task == \"mnli\" else \"validation\"\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "#     tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.695730447769165,\n",
       " 'eval_accuracy': 0.702,\n",
       " 'eval_f1': 0.7019361060880048,\n",
       " 'eval_precision': 0.7018778391154427,\n",
       " 'eval_recall': 0.702,\n",
       " 'eval_runtime': 12.0364,\n",
       " 'eval_samples_per_second': 41.541,\n",
       " 'epoch': 3.0,\n",
       " 'eval_mem_cpu_alloc_delta': 622592,\n",
       " 'eval_mem_gpu_alloc_delta': 0,\n",
       " 'eval_mem_cpu_peaked_delta': 0,\n",
       " 'eval_mem_gpu_peaked_delta': 289534464}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all samples results\n",
    "trainer.evaluate(eval_dataset=eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5558859705924988,\n",
       " 'eval_accuracy': 0.786,\n",
       " 'eval_f1': 0.7870509308975953,\n",
       " 'eval_precision': 0.7949385560675882,\n",
       " 'eval_recall': 0.786,\n",
       " 'eval_runtime': 12.6321,\n",
       " 'eval_samples_per_second': 39.582,\n",
       " 'epoch': 3.0,\n",
       " 'eval_mem_cpu_alloc_delta': -20480,\n",
       " 'eval_mem_gpu_alloc_delta': 0,\n",
       " 'eval_mem_cpu_peaked_delta': 20480,\n",
       " 'eval_mem_gpu_peaked_delta': 289534464}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only significant winner dataset\n",
    "trainer.evaluate(eval_dataset=eval_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All samples have 70% accuracy in validation\n",
    "Only significant winner samples have 78% accuracy in validation \n",
    "\n",
    "Evaluate on the same holdout set. Can try reducing the learning rate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run in SageMaker Training\n",
    "\n",
    "To run the same thing in sagemaker training we can use the following code. We first define our metrics to be collected, then define and launch our estimator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define metrics to track\n",
    "metric_definitions=[{\n",
    "        \"Name\": \"loss\",\n",
    "        \"Regex\": \".*loss:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"eval_loss\",\n",
    "        \"Regex\": \".*eval_loss:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"eval_accuracy\",\n",
    "        \"Regex\": \".*eval_accuracy:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"eval_f1\",\n",
    "        \"Regex\": \".*eval_f1:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"eval_precision\",\n",
    "        \"Regex\": \".*eval_precision:\\s([0-9\\\\.]+)\\s*\"\n",
    "    }, \n",
    "    {\n",
    "        \"Name\": \"learning_rate\",  \n",
    "        \"Regex\": \".*learning_rate:\\s([0-9\\\\.]+)\\s*\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"eval_recall\",  \n",
    "        \"Regex\": \".*eval_recall:\\s([0-9\\\\.]+)\\s*\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "\t'model_name':'squeezebert/squeezebert-mnli-headless',\n",
    "\t'output_dir':'/opt/ml/model',\n",
    "    'num_labels':2,\n",
    "    'epochs':2\n",
    "    \n",
    "\t# add your remaining hyperparameters\n",
    "\t# more info here https://github.com/huggingface/transformers/tree/v4.4.2/examples/text-classification\n",
    "}\n",
    "\n",
    "# git configuration to download our fine-tuning script\n",
    "git_config = {'repo': 'https://github.com/huggingface/transformers.git','branch': 'v4.4.2'}\n",
    "\n",
    "# creates Hugging Face estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "\tentry_point='train.py',\n",
    "\tsource_dir='container_training', #'./examples/text-classification',\n",
    "\tinstance_type='ml.p3.2xlarge',\n",
    "\tinstance_count=1,\n",
    "\trole=role,\n",
    "# \tgit_config=git_config,\n",
    "\ttransformers_version='4.4.2',\n",
    "\tpytorch_version='1.6.0',\n",
    "\tpy_version='py36',\n",
    "\thyperparameters = hyperparameters,\n",
    "    metric_definitions=metric_definitions\n",
    ")\n",
    "\n",
    "# starting the train job\n",
    "job_name = 'hf-headline-class-test'\n",
    "huggingface_estimator.fit(inputs = {'train':f's3://{bucket}/headlines/formatted_headlines.csv'}, \n",
    "                          wait=False,\n",
    "                         job_name = job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for hyperparameter tuning\n",
    "trainer.hyperparameter_search(\n",
    "    direction=\"maximize\", \n",
    "    backend=\"ray\", \n",
    "    n_samples=10, # number of trials\n",
    "    # n_jobs=2  # number of parallel jobs, if multiple GPUs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "# Michau/t5-base-en-generate-headline\n",
    "# mrm8488/t5-base-finetuned-summarize-news\n",
    "\n",
    "# ktrapeznikov/gpt2-medium-topic-news\n",
    "# mrm8488/bert-mini-finetuned-age_news-classification\n",
    "\n",
    "# QianWeiTech/GPT2-News\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
